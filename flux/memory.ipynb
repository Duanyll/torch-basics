{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import (\n",
    "    FluxTransformer2DModel,\n",
    "    FlowMatchEulerDiscreteScheduler,\n",
    "    FluxPipeline,\n",
    "    AutoencoderKL,\n",
    "    AutoencoderTiny,\n",
    ")\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from einops import rearrange, repeat, reduce\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.upcasting import (\n",
    "    LayerwiseUpcastingGranularity,\n",
    "    apply_layerwise_upcasting,\n",
    "    apply_cached_layerwise_upcasting_pytorch_layer,\n",
    "    get_module_size,\n",
    "    cast_trainable_parameters\n",
    ")\n",
    "from utils.offload_all import apply_offload_all_hook\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.bfloat16\n",
    "# dtype = torch.float32\n",
    "pipe = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-dev\", torch_dtype=torch.bfloat16\n",
    ")\n",
    "transformer: FluxTransformer2DModel = pipe.transformer\n",
    "transformer.train()\n",
    "transformer.enable_gradient_checkpointing()\n",
    "transformer.requires_grad_(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "print(f\"Before Installing LoRA: {get_module_size(pipe.transformer) / 1e9:.2f} GB\")\n",
    "rank = 128\n",
    "target_modules = [\n",
    "        \"attn.to_k\",\n",
    "        \"attn.to_q\",\n",
    "        \"attn.to_v\",\n",
    "        \"attn.to_out.0\",\n",
    "        \"attn.add_k_proj\",\n",
    "        \"attn.add_q_proj\",\n",
    "        \"attn.add_v_proj\",\n",
    "        \"attn.to_add_out\",\n",
    "        \"ff.net.0.proj\",\n",
    "        \"ff.net.2\",\n",
    "        \"ff_context.net.0.proj\",\n",
    "        \"ff_context.net.2\",\n",
    "]\n",
    "\n",
    "transformer_lora_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=rank,\n",
    "    init_lora_weights=True,\n",
    "    target_modules=target_modules,\n",
    "    lora_bias=True,\n",
    ") # type: ignore\n",
    "\n",
    "transformer.add_adapter(transformer_lora_config)\n",
    "# cast_trainable_parameters(transformer, dtype=dtype)\n",
    "print(f\"After Installing LoRA: {get_module_size(pipe.transformer) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before Installing Hooks: {get_module_size(pipe.transformer) / 1e9:.2f} GB\")\n",
    "apply_layerwise_upcasting(\n",
    "    pipe.transformer,\n",
    "    storage_dtype=torch.float8_e4m3fn,\n",
    "    compute_dtype=dtype,\n",
    "    granularity=LayerwiseUpcastingGranularity.PYTORCH_LAYER,\n",
    ")\n",
    "apply_offload_all_hook(\n",
    "    pipe,\n",
    "    execution_device=device,\n",
    "    offload_device=\"cpu\",\n",
    "    submodules=[\"vae\", \"text_encoder\", \"text_encoder_2\", \"transformer\"],\n",
    ")\n",
    "# def _cast(x):\n",
    "#     if x.dtype == torch.bfloat16:\n",
    "#         return x.to(torch.float32)\n",
    "#     return x\n",
    "# transformer._apply(_cast)\n",
    "print(f\"After Installing Hooks: {get_module_size(pipe.transformer) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dtypes():\n",
    "    lora_layer: Any = transformer.transformer_blocks[0].attn.to_q # type: ignore\n",
    "    print(f\"Base layer dtype: {lora_layer.base_layer.weight.dtype}\")\n",
    "    print(f\"LoRA layer dtype: {lora_layer.lora_A.default.weight.dtype}\")\n",
    "    if lora_layer.lora_A.default.weight.grad is not None:\n",
    "        print(f\"LoRA grad dtype: {lora_layer.lora_A.default.weight.grad.dtype}\")\n",
    "        \n",
    "show_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnable_params = list(filter(lambda p: p.requires_grad, transformer.parameters()))\n",
    "learnable_params_count = sum(p.numel() for p in learnable_params)\n",
    "print(f\"Learnable Parameters Count: {learnable_params_count / 1e6:.2f} M\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    transformer.parameters(), lr=1e-4, betas=(0.9, 0.999), weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = torch.randn(1, 8192, 64, device=device, dtype=dtype)\n",
    "encoder_hidden_states = torch.randn(1, 512, 4096, device=device, dtype=dtype)\n",
    "pooled_projections = torch.randn(1, 768, device=device, dtype=dtype)\n",
    "timestep = torch.tensor([1.], device=device, dtype=dtype)\n",
    "img_ids = torch.randn(8192, 3, device=device, dtype=dtype)\n",
    "txt_ids = torch.randn(512, 3, device=device, dtype=dtype)\n",
    "guidance = torch.tensor([3.5], device=device, dtype=torch.float32)\n",
    "\n",
    "print(f\"Initial Memory Usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "res = transformer(\n",
    "    hidden_states=hidden_states,\n",
    "    encoder_hidden_states=encoder_hidden_states,\n",
    "    pooled_projections=pooled_projections,\n",
    "    timestep=timestep,\n",
    "    img_ids=img_ids,\n",
    "    txt_ids=txt_ids,\n",
    "    guidance=guidance,\n",
    "    return_dict=True\n",
    ")\n",
    "print(f\"After Forward Memory Usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean(res.sample)\n",
    "loss.backward()\n",
    "print(f\"After Backward Memory Usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "show_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "print(f\"After Optimizer Step Memory Usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "show_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before = time.time()\n",
    "optimizer.zero_grad()\n",
    "show_dtypes()\n",
    "res = transformer(\n",
    "    hidden_states=hidden_states,\n",
    "    encoder_hidden_states=encoder_hidden_states,\n",
    "    pooled_projections=pooled_projections,\n",
    "    timestep=timestep,\n",
    "    img_ids=img_ids,\n",
    "    txt_ids=txt_ids,\n",
    "    guidance=guidance,\n",
    "    return_dict=True\n",
    ")\n",
    "loss = torch.mean(res.sample)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "time_after = time.time()\n",
    "print(f\"After Second Step Memory Usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "print(f\"Time Taken: {time_after - time_before:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before = time.time()\n",
    "optimizer.zero_grad()\n",
    "for i in range(3):\n",
    "    res = transformer(\n",
    "        hidden_states=hidden_states,\n",
    "        encoder_hidden_states=encoder_hidden_states,\n",
    "        pooled_projections=pooled_projections,\n",
    "        timestep=timestep,\n",
    "        img_ids=img_ids,\n",
    "        txt_ids=txt_ids,\n",
    "        guidance=guidance,\n",
    "        return_dict=True\n",
    "    )\n",
    "    loss = torch.mean(res.sample)\n",
    "    print(f\">> Iteration {i} Before Backward: \")\n",
    "    show_dtypes()\n",
    "    loss.backward()\n",
    "    print(f\">> Iteration {i} After Backward: \")\n",
    "    show_dtypes()\n",
    "optimizer.step()\n",
    "time_after = time.time()\n",
    "print(f\"After Second Step Memory Usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "print(f\"Time Taken: {time_after - time_before:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
