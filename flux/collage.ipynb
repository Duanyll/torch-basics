{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspaces/torch-basics/\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2\n",
    "import kornia\n",
    "import logging\n",
    "from rich import print\n",
    "from rich.logging import RichHandler\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(message)s\",\n",
    "    datefmt=\"[%X]\",\n",
    "    handlers=[RichHandler(rich_tracebacks=True)],\n",
    ")\n",
    "\n",
    "from flux_control.utils.describe import describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = torchvision.io.read_video(\n",
    "    \"./flux/assets/video.mp4\", output_format=\"TCHW\", pts_unit=\"sec\"\n",
    ")\n",
    "video_frames = video[0].float() / 255.0\n",
    "describe(video)\n",
    "describe(video_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.flow import (\n",
    "    load_raft_model,\n",
    "    compute_aggregated_flow,\n",
    "    unload_raft_model,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_raft_model(device=device)\n",
    "\n",
    "selected_frames = video_frames[80:100].to(device)\n",
    "flow, target_idx = compute_aggregated_flow(selected_frames)\n",
    "describe(flow)\n",
    "unload_raft_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat, reduce\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_flow(flow):\n",
    "    if len(flow.shape) == 4:\n",
    "        flow = rearrange(flow, \"1 c h w -> c h w\")\n",
    "    flow = flow.cpu().numpy()\n",
    "    flow = rearrange(flow, \"c h w -> h w c\")\n",
    "    # Use Hue, Saturation, Value colour model\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    hsv[..., 2] = 255\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang / np.pi / 2 * 180\n",
    "    hsv[..., 1] = np.clip(mag * 255 / 24, 0, 255)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return Image.fromarray(bgr)\n",
    "\n",
    "def visualize_image(image):\n",
    "    if len(image.shape) == 4:\n",
    "        image = rearrange(image, \"1 c h w -> c h w\")\n",
    "    image = image.cpu().numpy()\n",
    "    image = rearrange(image, \"c h w -> h w c\")\n",
    "    return Image.fromarray((image * 255).astype(np.uint8))\n",
    "\n",
    "display(visualize_image(selected_frames[0]))\n",
    "display(visualize_image(selected_frames[target_idx]))\n",
    "display(visualize_flow(flow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.warp import forward_warp\n",
    "\n",
    "warp_result = forward_warp(selected_frames[0], selected_frames[target_idx], flow)\n",
    "describe(warp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(visualize_image(warp_result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.depth import (\n",
    "    load_depth_model,\n",
    "    estimate_depth,\n",
    "    unload_depth_model,\n",
    ")\n",
    "\n",
    "load_depth_model(device=device)\n",
    "depth = estimate_depth(selected_frames[0])\n",
    "describe(depth)\n",
    "unload_depth_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_greyscale(image):\n",
    "    image = image.squeeze().cpu().numpy() # [h, w]\n",
    "    image = repeat(image, \"h w -> h w c\", c=3)\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    return Image.fromarray(image)\n",
    "\n",
    "display(visualize_greyscale(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.segmentation import load_segmentation_model, generate_masks, unload_segmentation_model\n",
    "\n",
    "load_segmentation_model(device=device)\n",
    "masks = generate_masks(selected_frames[0])\n",
    "describe(masks)\n",
    "unload_segmentation_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.affine import compute_transform_data_structured, apply_transforms\n",
    "\n",
    "transform, dropped = compute_transform_data_structured(flow, depth, masks)\n",
    "describe(transform)\n",
    "describe(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped, grid, warped_regions, warped_alpha = apply_transforms(\n",
    "    selected_frames[0], depth, transform\n",
    ")\n",
    "display(visualize_image(warped))\n",
    "# display(visualize_greyscale(warped_regions))\n",
    "# display(visualize_greyscale(warped_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(warped)\n",
    "describe(grid)\n",
    "describe(warped_regions)\n",
    "describe(warped_alpha)\n",
    "\n",
    "warped_alpha = torch.clamp(warped_alpha, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.video import splat_lost_regions\n",
    "\n",
    "warped, grid, warped_alpha = splat_lost_regions(\n",
    "    selected_frames[0],\n",
    "    selected_frames[target_idx],\n",
    "    flow,\n",
    "    warped,\n",
    "    grid,\n",
    "    warped_regions,\n",
    "    warped_alpha,\n",
    ")\n",
    "\n",
    "display(visualize_image(warped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.dexined import load_dexined_model, estimate_edges\n",
    "\n",
    "load_dexined_model(device=device)\n",
    "edges = estimate_edges(selected_frames[target_idx])\n",
    "describe(edges)\n",
    "display(visualize_greyscale(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.palette import extract_palette_from_masked_image, show_color_palette\n",
    "palette, _ = extract_palette_from_masked_image(\n",
    "    selected_frames[0], torch.ones_like(warped_alpha), 5\n",
    ")\n",
    "describe(palette)\n",
    "show_color_palette(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.video import encode_color_palette\n",
    "\n",
    "palettes, locations = encode_color_palette(selected_frames[0], dropped, area_threshold=0.05)\n",
    "describe((palettes, locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color_palette(palettes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from flux_control.utils.common import meshgrid_to_ij\n",
    "\n",
    "def show_palette_with_locations(image, palettes, locations):\n",
    "    c, h, w = image.shape\n",
    "    image = rearrange(image, \"c h w -> h w c\")\n",
    "    image = image.cpu().numpy()\n",
    "    plt.imshow(image)\n",
    "    locations_ij = meshgrid_to_ij(locations, h, w)\n",
    "    palettes = palettes.cpu().numpy()\n",
    "    locations_ij = locations_ij.cpu().numpy()\n",
    "    for i in range(palettes.shape[0]):\n",
    "        palette = palettes[i]\n",
    "        loc = locations_ij[i]\n",
    "        plt.scatter(loc[1], loc[0], color=palette, s=100, marker=\"o\", edgecolors=\"black\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "show_palette_with_locations(\n",
    "    selected_frames[0] * (1 - warped_regions), palettes, locations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, h, w = selected_frames[0].shape\n",
    "dropped_masks_qualify = [mask for mask in dropped if mask[\"area\"] > h * w * 0.05]\n",
    "describe(dropped_masks_qualify)\n",
    "\n",
    "for mask in dropped_masks_qualify:\n",
    "    mask_torch = torch.from_numpy(mask[\"mask\"]).to(device)\n",
    "    # display(visualize_image(selected_frames[0] * mask_torch))\n",
    "    palettes, locations = extract_palette_from_masked_image(\n",
    "        selected_frames[0], mask_torch, max_colors=3, min_colors=1\n",
    "    )\n",
    "    show_color_palette(palettes)\n",
    "    show_palette_with_locations(selected_frames[0] * mask_torch, palettes, locations)\n",
    "    print(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette, locations = extract_palette_from_masked_image(\n",
    "    selected_frames[0], torch.ones_like(warped_alpha), 5\n",
    ")\n",
    "show_color_palette(palette)\n",
    "show_palette_with_locations(selected_frames[0], palette, locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flux_control.datasets.collage.palette import extract_palette_from_masked_image_with_spatial\n",
    "\n",
    "palette, locations = extract_palette_from_masked_image_with_spatial(\n",
    "    selected_frames[0], torch.ones_like(warped_alpha), 5\n",
    ")\n",
    "show_color_palette(palette)\n",
    "show_palette_with_locations(selected_frames[0], palette, locations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
